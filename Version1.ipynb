{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RashmiLnu/aqa-test-tools/blob/test-branch-rashmi/Version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW7h6VD2xC6a",
        "outputId": "754ef9e4-f5f8-46b2-afd0-5fb13a3306f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain together openai faiss-cpu tiktoken\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import Together\n",
        "\n",
        "# Paste your Together.ai API key here (inside quotes)\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"Token\"\n",
        "\n",
        "# Load the LLM from Together.ai (you can switch models later)\n",
        "llm = Together(\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=512\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "NtPGB4JfxQqt",
        "outputId": "a65ccc83-43f2-462f-c5cb-a80df9add406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3999486881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTogether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Paste your Together.ai API key here (inside quotes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TOGETHER_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"87088e96b65a24446fb3ec73d7bd30290d473ab6d0f8a84e95ec4a2e0cd5844f\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mllms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;31m# If not in interactive env, raise warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e52bb9b",
        "outputId": "367cf54d-25dc-4b79-f7de-0fd6f114c7c3"
      },
      "source": [
        "!pip install -q langchain-community"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9e0ba93",
        "outputId": "313efa6d-22ee-483c-b98a-2a72091101a2"
      },
      "source": [
        "!pip install -U langchain-together"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-together\n",
            "  Downloading langchain_together-0.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain-together) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-together) (0.3.68)\n",
            "Collecting langchain-openai<0.4,>=0.3 (from langchain-together)\n",
            "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-together) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.20.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (4.14.1)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (2.11.7)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai<0.4,>=0.3->langchain-together) (1.93.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai<0.4,>=0.3->langchain-together) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-together) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-together) (2025.7.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain-together) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.16.0)\n",
            "Downloading langchain_together-0.3.0-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai, langchain-together\n",
            "Successfully installed langchain-openai-0.3.27 langchain-together-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe5a52e5"
      },
      "source": [
        "import os\n",
        "from langchain_together import Together\n",
        "\n",
        "# Paste your Together.ai API key here (inside quotes)\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"Token\"\n",
        "\n",
        "# Load the LLM from Together.ai (you can switch models later)\n",
        "llm = Together(\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=512\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Define prompt template\n",
        "template = \"\"\"\n",
        "You are a debugging assistant.\n",
        "Given the following test failure and commit diff, determine whether the commit likely caused the failure.\n",
        "\n",
        "Test Failure:\n",
        "{failure}\n",
        "\n",
        "Commit Diff:\n",
        "{diff}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"failure\", \"diff\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "test_failure = \"NullPointerException at NullHandler.java:42\"\n",
        "commit_diff = \"\"\"\n",
        "diff --git a/NullHandler.java b/NullHandler.java\n",
        "@@ -40,6 +40,7 @@\n",
        " public void handle() {\n",
        "     Object obj = null;\n",
        "     obj.toString();  // ← added line\n",
        " }\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "chain = prompt | llm\n",
        "result = chain.invoke({\n",
        "    \"failure\": test_failure,\n",
        "    \"diff\": commit_diff\n",
        "})\n",
        "\n",
        "print(\"🤖 GPT Response:\\n\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W6agZt6yPYW",
        "outputId": "b8740eea-45ca-43fc-da72-933ec38e3106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 GPT Response:\n",
            " It is likely that the commit caused the failure because the added line of code `obj.toString();` is causing a NullPointerException at line 42 of the `NullHandler` class. The `toString()` method is called on a null object, which is not allowed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnNaGqCW20Rt",
        "outputId": "24e0c02e-bbe5-4bcd-fd46-2ae8f8dbc46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Load open-source embedding model\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # or use bge-small-en\n",
        "\n",
        "# Simulate commit diffs\n",
        "commit_diffs = [\n",
        "    (\"sha1\", \"Added null check to NullHandler.java\"),\n",
        "    (\"sha2\", \"Refactored config loading\"),\n",
        "    (\"sha3\", \"Removed unused function from TestRunner\"),\n",
        "    (\"sha4\", \"Introduced obj.toString() in NullHandler.java\"),\n",
        "    (\"sha5\", \"Added logging in exception handler\")\n",
        "]\n",
        "\n",
        "# Embed each diff\n",
        "texts = [text for _, text in commit_diffs]\n",
        "embeddings = embed_model.encode(texts, convert_to_numpy=True)\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "# Store commit metadata separately\n",
        "sha_lookup = [sha for sha, _ in commit_diffs]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "caaa35397f094e7b814ebda86e0702c3",
            "2b6c2c83fcb4474d9bbfb46244560f39",
            "34dcbde653d749718ba058321d9e7b2a",
            "f6d6a238cdb04848814c5c76b5723d1a",
            "2884872334cf42169b383d57127058d6",
            "1099f1cfdc1b49c7baf96d285bcb4e00",
            "250870d2b7d24f21be0d3b36c8e7b3e9",
            "8e979a464ff44457a01d88051d253bf1",
            "8018ad871b9947a38fab8f07c9800663",
            "3899b176e168480d8cc6916dd2bdb3d0",
            "4fb3590a93294a259ece58019aa834d2",
            "052db8033fed4e8ab748b6a848171f44",
            "59322f7621fe40afbaa8f2c3a3389e04",
            "0ebdfd86d959401990ab993f9795a058",
            "6be87ed94980406a89448c3a602051fb",
            "697a149721e14e4293f010bb26b4e842",
            "ad4665690917418e9f61df882b294241",
            "ab36b6bf78914a599ca7a67f6de87034",
            "545d6f49cb5a436abb3ebf9b895b1ffc",
            "477b1de23bcd419db624245320b334bd",
            "2d9118cbbfde4c14b970fe0d6f6f88a7",
            "2f387984f1d641cbac205d0341cf8319",
            "439033de40494cdabeca3487c9e5a954",
            "7abf52d3ec954ad0b58feb66be0d8e73",
            "f179daa49a62465bbe7663af077297a7",
            "08bb795e04ef4c5aa4772973c0cdf573",
            "def274596d25402da7ba41a60f22c6ac",
            "b5dbebfe11a540d3a5942ea57f4306bf",
            "de73df6e895549c8b3d11bbe79d499fb",
            "a40fc745b041446c99e2d9bbd9feebc3",
            "a420b78278bf4912b2134b9c802bba64",
            "9b6eb4392fb34382813e502e00a8eb28",
            "81e05ce7ee374d959fb2c0a3d3d12a27",
            "b038d024f5394340ace26d0eec32077f",
            "5688263d7f6646189103a228266a3861",
            "7c1ba74106dd423caba214f4a326b456",
            "f5c1c800bf184dc1913a5418cfd3c30c",
            "2cd0cfebadf94fddad0425c34e7c5ae9",
            "1924b8f616a446068f1968f737c8e41f",
            "ce16df1cd4324c5ab6fc6f2205d7c76f",
            "e11a41670a20449782a9407fcc261dec",
            "3fa6cd129f42490f8e9a77e6492b956d",
            "9988d4151a904e279702ad3e3d4fce6e",
            "db55b65959fa4e57addfb0543c110df3",
            "0bf7b93840c1499b94126682123e2ed2",
            "f34e82c1937241e8b9856216433c773f",
            "53f8296e21694dfaa5e84a7d0c34eadc",
            "677d591b09db44c5aebca9fc06c36df9",
            "020301140c774d719e5c27eca4a047fa",
            "23e90c31d64c44c0aaf16f908672c886",
            "f3ba31066e37419c87654e50d1db0511",
            "17a9eb2076954061b39432681971da20",
            "c57c32fd690146bfb0383f485bf46257",
            "fe3a0b86271f4dd0911cbad83da692fd",
            "0dbcbe170a3c48398fb9a46ecf210f8a",
            "45024ca571bd417fa665dcb684d55c94",
            "538416d8ab2647abaff19ade64c3a63a",
            "03854ddec77f407e9eecfeebe461f639",
            "383fac9dd02d4650a44ee38986c197b4",
            "c5ceb243eb3d4d1ba04997e9c0907995",
            "843c9c3d2cff4153a171d07807b1b132",
            "4846041a3a8040c1b2fdf25f9234c9f3",
            "e5038ca7783f493e87dabdd0fb6ceb13",
            "8d77301f24c142218f311f50f5234f74",
            "d61a90f9a67e4d868ffe85ead2153d90",
            "48f7bc2cf7a54aebb25d2a56bd658216",
            "d411e4660a174e30be22d326afc383e8",
            "a79b6f509d02454bb3cd8eaaed4b9eaf",
            "9ee49ce457054290aebb262fdfa68300",
            "4270e4697a0741ea93da4df2ba5a9614",
            "2ab9e2c1f5294b5a805b2ee7d72ea0be",
            "52d022c8bf5a41cdac6e660ed58e31ab",
            "3772114f016648968749f5eaf991d39f",
            "e2a5ed312caf411096c70ff5c727c5d1",
            "582ae088bb964cb2a58647fcf0675f6b",
            "31128f93a379407ca0e6020646943b36",
            "2aeb583cc83f4606893063ce68d5fd48",
            "e7ad4231526e4168b2758c62ef7f4d5c",
            "4145d80e1f854c7aa3adb196c1dd0a59",
            "3e5268cf24d54fc4ad566bbdfa5bc0e3",
            "866d18515c4f4575b5a10dad9f91fe2d",
            "a6c334a78aaa42d78b4174cdc1d33f2e",
            "437b167df15446118fe38e0c34e0baff",
            "82319a440fb648498d1f9405de9a4d15",
            "65e51e6c3da348b8aaa3faa2364c6f8e",
            "486fd7921e2f4732beb719c391625b0c",
            "1c3d62f7c1d14b2287e81ae0cc27d6e4",
            "c550da9618ab49868f3b3f580a4a2ec5",
            "358bf1d644254ca9ab9e90be7e2225fd",
            "18af2840bb924c05bd2b443034d30b64",
            "874e812fb46642c7a4c9e21ad0228d43",
            "652767422b174c39b6e9b91dfb2366be",
            "23b6eb823c214d959267f276ed95a228",
            "90bfbd6b7d7845b7a0e664cd714f4722",
            "e0b6a96221c5443da979e9367d622e95",
            "bf2ad32e32304f7789627714acce338e",
            "683bab45ae90480ebe2798aa4ba1b279",
            "1f225331b5b447caa28c11cc95a883e3",
            "6e469499c225436c887b2bc0719a5c25",
            "aa140a5fa2e74eb5b9d93ab333867398",
            "b5e5828359d74847b098b2297d7f159e",
            "4780886486a64a1dba9c361b6d60bbb7",
            "9c90c3df9dd04e2dae21981a78e79110",
            "128bbaecb81941a2938fbe5c8b9604b0",
            "cec4c02fcd064f759a44d43811b4d34e",
            "1019fab340f84bce98d1892dcb04c5d1",
            "ea941b626a82461f9a44e061a57cc1fc",
            "59cdc802324343a0acaff16ff94a5364",
            "b47b616451ad4fccaa8f4de129964c62",
            "e7ca82c169db4c1b8a72be9a17d89a91",
            "574b629825a54dc5aadc95ca1c8348ed",
            "eb100a69f72c4ff49e716edd148a5881",
            "fa9661975bc2452abd00c0c36767ddb0",
            "7b538aae7a5c4d5b995415074a9ccc91",
            "eeb3627f41064d14be0ff9e349fac71a",
            "6ea7b2c6c4e349f9a8614d0112027665",
            "db8a1c4daf65402197be94bd202017cc",
            "0d4109a25ec3469db9e0acebd661f8a9",
            "92c5c7a26249450084fe3829ee753924",
            "8f86ab90fc0c47889f16dbcd4d77d0ac",
            "5a60babab3a74a50928c34994c2856a9"
          ]
        },
        "id": "ni717d8U5e1C",
        "outputId": "647efda2-8ff2-4745-e4d0-17c73554c38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caaa35397f094e7b814ebda86e0702c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "052db8033fed4e8ab748b6a848171f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "439033de40494cdabeca3487c9e5a954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b038d024f5394340ace26d0eec32077f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf7b93840c1499b94126682123e2ed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45024ca571bd417fa665dcb684d55c94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d411e4660a174e30be22d326afc383e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ad4231526e4168b2758c62ef7f4d5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "358bf1d644254ca9ab9e90be7e2225fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa140a5fa2e74eb5b9d93ab333867398"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "574b629825a54dc5aadc95ca1c8348ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test failure text\n",
        "test_failure_context = \"NullPointerException at NullHandler.java:42 in handle()\"\n",
        "\n",
        "# Embed the failure\n",
        "query_embedding = embed_model.encode([test_failure_context])\n",
        "\n",
        "# Search for top 3 most similar diffs\n",
        "D, I = index.search(query_embedding, 3)\n",
        "top_matches = [(sha_lookup[i], commit_diffs[i][1]) for i in I[0]]\n",
        "\n",
        "print(\"🔍 Top relevant commit diffs:\\n\")\n",
        "for sha, diff in top_matches:\n",
        "    print(f\"Commit {sha}:\\n{diff}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQzf5L3l6HHN",
        "outputId": "c236eba3-7705-4937-b0c5-655c2ae365d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Top relevant commit diffs:\n",
            "\n",
            "Commit sha1:\n",
            "Added null check to NullHandler.java\n",
            "\n",
            "Commit sha4:\n",
            "Introduced obj.toString() in NullHandler.java\n",
            "\n",
            "Commit sha5:\n",
            "Added logging in exception handler\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are a debugging assistant.\n",
        "\n",
        "A test failed with the following message:\n",
        "{failure}\n",
        "\n",
        "Here is a commit diff that was semantically similar:\n",
        "{diff}\n",
        "\n",
        "Do you think this commit caused the failure? Why or why not?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"failure\", \"diff\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n"
      ],
      "metadata": {
        "id": "0LiPUzbA7-WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🤖 GPT-style analysis:\\n\")\n",
        "\n",
        "for sha, diff in top_matches:\n",
        "    print(f\"🧩 Commit {sha}:\")\n",
        "    response = chain.invoke({\n",
        "        \"failure\": test_failure_context,\n",
        "        \"diff\": diff\n",
        "    })\n",
        "    print(response)\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7C-duv58Bdx",
        "outputId": "953c866f-96bc-479b-950b-5ba2b9d374d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 GPT-style analysis:\n",
            "\n",
            "🧩 Commit sha1:\n",
            "\n",
            "Yes, it is likely that this commit caused the failure. The commit added a null check to the code, which means that if a null value is passed to the method, it will throw a NullPointerException. This could be causing the test to fail because the test is passing a null value to the method. It is important to verify that the test is passing the correct values to the method to ensure that the test passes.\n",
            "------------------------------------------------------------\n",
            "🧩 Commit sha4:\n",
            "\n",
            "I don't have enough information to determine if this commit caused the failure. It's possible that the failure was due to a different issue, or that the commit was unrelated to the failure. Without more context, it's difficult to say for sure.\n",
            "------------------------------------------------------------\n",
            "🧩 Commit sha5:\n",
            "\n",
            "I'm not sure if this commit caused the failure. It's possible that the logging change caused some unexpected behavior in the code that led to the NullPointerException. However, it's also possible that the failure was caused by some other code change or bug that was introduced after the commit. Without more information, it's difficult to say for sure.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_diff_text = \"\"\n",
        "\n",
        "for sha, diff in top_matches:\n",
        "    combined_diff_text += f\"--- Commit {sha} ---\\n{diff}\\n\\n\"\n"
      ],
      "metadata": {
        "id": "fGZLq7VdARod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "combined_template = \"\"\"\n",
        "You are a debugging assistant helping identify the root cause of a test failure.\n",
        "\n",
        "Here is the test failure:\n",
        "{failure}\n",
        "\n",
        "Here are the top 3 semantically related commits:\n",
        "{diffs}\n",
        "\n",
        "Based on the diff content and the test failure, which commit is most likely responsible? Explain your reasoning.\n",
        "\"\"\"\n",
        "\n",
        "combined_prompt = PromptTemplate(\n",
        "    input_variables=[\"failure\", \"diffs\"],\n",
        "    template=combined_template\n",
        ")\n",
        "\n",
        "# Create runnable chain\n",
        "combined_chain = combined_prompt | llm\n"
      ],
      "metadata": {
        "id": "fWmt6Ii0ATHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = combined_chain.invoke({\n",
        "    \"failure\": test_failure_context,\n",
        "    \"diffs\": combined_diff_text\n",
        "})\n",
        "\n",
        "print(\"🤖 Final Verdict:\\n\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ6iKc4iAWSv",
        "outputId": "aef8317a-eb40-45ab-e35e-1bed93275113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Final Verdict:\n",
            "\n",
            "\n",
            "Commit sha1 is the most likely responsible for the test failure. The commit introduced a null check to NullHandler.java, which means that if the object passed to the handle() method is null, a NullPointerException will be thrown. This is consistent with the test failure message, which indicates that a NullPointerException occurred at line 42 of NullHandler.java.\n",
            "\n",
            "Commit sha4 introduced obj.toString() in NullHandler.java, but this commit does not seem to be related to the test failure since it does not involve any null checks.\n",
            "\n",
            "Commit sha5 added logging in exception handler, but this commit also does not seem to be related to the test failure since it does not involve any null checks.\n",
            "\n",
            "Therefore, based on the information provided, commit sha1 is the most likely responsible for the test failure.\n"
          ]
        }
      ]
    }
  ]
}
